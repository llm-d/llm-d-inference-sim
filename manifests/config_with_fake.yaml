model: "Qwen/Qwen2-0.5B"
max-loras: 2
max-cpu-loras: 5
max-num-seqs: 5
mode: "random"
time-to-first-token: "2s"
inter-token-latency: "1s"
kv-cache-transfer-latency: "100ms"
seed: 100100100
fake-metrics:
  running-requests: 16
  waiting-requests: 3 
  kv-cache-usage: 0.3
  request-success-total:
    stop: 20
  request-prompt-tokens: [ 10, 20, 30, 15 ]
  request-generation-tokens: [ 50, 60, 40 ]
  request-params-max-tokens: [ 128, 256, 512 ]
  request-max-generation-tokens: [0, 0, 10, 20]
  loras:
  - '{"running":"lora1,lora2","waiting":"lora3","timestamp":1257894567}'
  - '{"running":"lora1,lora3","waiting":"","timestamp":1257894569}'
  ttft-buckets-values: [10, 20, 30, 10]
  tpot-buckets-values: [0, 0, 10, 20, 30]
